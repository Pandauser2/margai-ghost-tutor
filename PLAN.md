# MargAI Ghost Tutor â€“ 14-day pilot implementation plan

**Overall Progress:** `100%`

---

## TLDR

Build a **14-day pilot** where students ask doubts over **Telegram** and get answers from RAG over their instituteâ€™s PDFs. Multi-tenant via **Pinecone namespaces** (`institute_id`). When the model canâ€™t answer, **ask one clarifying question** first; escalate to TA only after that (or if the student replies â€œescalateâ€). **Manual** PDF ingestion (teacher sends PDFs â†’ you run script â†’ upsert to Pinecone) and **manual** weekly report and log cleanup. Goal: validate the flow and collect success stories to sell **WhatsApp API** in Month 2.

---

## Critical decisions

- **Telegram first** â€” Free, ~5 min setup; WhatsApp (e.g. WATI/Interakt) in Month 2 after success stories.
- **Pinecone namespace = `institute_id`** â€” One namespace per coaching center; backend always queries only that namespace so Institute A never sees Institute B data.
- **Knowledge-lock** â€” Strict for content (answer only from context; â€œThis wasnâ€™t coveredâ€¦ Iâ€™ve flagged this for your teacher!â€ or ESCALATE); flexible for tone; allow general English/Math logic to explain steps, never new facts.
- **Clarify before escalate** â€” On ESCALATE or empty retrieval, send one clarifying message; only escalate when the student later replies â€œescalateâ€ (or similar) or we get ESCALATE again on follow-up.
- **Manual triggers only** â€” No cron: ingestion, weekly report, and log cleanup are all run manually (script or n8n â€œRun workflowâ€).
- **Reuse extraction approach** â€” Same text+OCR logic as `upsc-test-engine` (pdfplumber, PyMuPDF, Tesseract); optional fallback later: LlamaParse/Unstructured.io if messy PDFs become a problem.
- **Risks as fallback** â€” Cold start (Vercel) and messy PDF parsing are documented; do not change the plan now; add logs where possible to detect them.

---

## Tasks

- [x] ğŸŸ© **Step 1: Supabase schema and config**
  - [x] ğŸŸ© Create `institutes` table: `id` (SERIAL/IDENTITY), `slug` (unique), `email_for_report`, `ta_telegram_id`, optional `created_at`.
  - [x] ğŸŸ© Create `uploads` table: `id`, `institute_id` (FK â†’ `institutes.id`), `file_path`, `filename`, `status` (processing/completed/failed), `created_at`, optional `completed_at`, `error_message`.
  - [x] ğŸŸ© Create `query_logs` table: `id`, **`institute_id` (not null, FK â†’ `institutes.id`)**, `student_telegram_id`, `student_name`, `timestamp`, `query_text`, `is_photo`, `escalated`, optional `clarification_sent`, `replied_at`. Ensure every row is linked to an institute.
  - [x] ğŸŸ© Enable **RLS** on `institutes` and `query_logs` (e.g. policy `FOR ALL USING (institute_id = 1)` for pilot so rows are scoped by institute). n8n/backend uses service_role and bypasses RLS.

- [x] ğŸŸ© **Step 2: Pinecone index and namespace convention**
  - [x] ğŸŸ© Create Pinecone serverless index with dimension matching embedding model (e.g. 768).
  - [x] ğŸŸ© Document convention: upsert and query always use `namespace = institute_id` (or stable slug); one namespace per institute.

- [x] ğŸŸ© **Step 3: PDF ingestion pipeline (Phase 1)**
  - [x] ğŸŸ© Backend: upload endpoint or script that accepts PDF (reuse upsc-test-engine pattern: save to `upload_dir`, return path/doc_id).
  - [x] ğŸŸ© Extraction: call or reuse logic from `upsc-test-engine` (text + OCR via `pdf_extraction_service.py` style: PyMuPDF, pdfplumber, Tesseract hin+eng where needed). Insert `uploads` row (status = processing).
  - [x] ğŸŸ© Chunk: 800â€“1000 chars, overlap 100â€“200; stable IDs (e.g. slug + hash(file_path + chunk_index)).
  - [x] ğŸŸ© Embed with Gemini embedding API; upsert to Pinecone with `namespace = institute_id`. Update `uploads.status = 'completed'` or `'failed'` + `error_message`.
  - [x] ğŸŸ© Manual input: institute slug/name with uniqueness check. On failure, email ALERT_EMAIL.

- [x] ğŸŸ© **Step 4: Telegram webhook and chat â†’ institute mapping (Phase 2)**
  - [x] ğŸŸ© **Build and host the Telegram webhook on Vercel** (or chosen runtime): register bot, set webhook URL, validate secret_token on incoming requests.
  - [x] ğŸŸ© **Map incoming `chat_id` (or bot context) to `institute_id` in Supabase** so the handler knows which Pinecone namespace to query. For pilot: single bot â†’ single institute (e.g. hardcode `institute_id = 1` or read from config). For multi-tenant later: use a Supabase lookup (e.g. table mapping chat_id/bot to institute_id, or `institutes` row per bot).
  - [x] ğŸŸ© On message: parse `message.from.id`, `message.chat.id`, `message.text`, `message.photo`; resolve `institute_id` via the mapping above before inserting into `query_logs` and querying Pinecone.

- [x] ğŸŸ© **Step 5: RAG + reply flow (Phase 2)**
  - [x] ğŸŸ© Insert into `query_logs` (institute_id, student_telegram_id, student_name, query_text, is_photo, escalated=false).
  - [x] ğŸŸ© Embed query text; Pinecone query with `namespace = institute_id`, top K 5â€“10.
  - [x] ğŸŸ© Build prompt: Knowledge-lock system prompt (Â§5.3 EXPLORATION) + â€œIf you cannot answer from context, respond with exactly: ESCALATE.â€ User = context chunks + query (+ image if photo). Call Gemini **gemini-2.5-flash** (text + optional image).
  - [x] ğŸŸ© If response normalized === "ESCALATE": send clarifying message to student; set `clarification_sent = true` on row; do not escalate. If next message from same student is â€œescalateâ€ (normalized): set `escalated = true` on previous row; reply to student; send TA full message (From: student, text + image) via Telegram using `institutes.ta_telegram_id`. Else: reply to student with Gemini answer via Telegram sendMessage.
  - [x] ğŸŸ© Empty/weak retrieval: same clarifying-question path. On API failure: email ALERT_EMAIL, reply â€œSomething went wrong.â€

- [x] ğŸŸ© **Step 6: Weekly report and cleanup (Phase 3)**
  - [x] ğŸŸ© Weekly report: manual trigger; query `query_logs` last 7 days, institute_id=1; compute total queries, escalation %, top 5 topics (JEE/NEET/UPSC placeholder keywords); optional top students and who escalated. Generate email body text only; do not send (you send manually).
  - [x] ğŸŸ© Cleanup: manual trigger; delete from `query_logs` where `timestamp` < now âˆ’ 30 days.

- [x] ğŸŸ© **Step 7: Observability (optional, not blocking)**
  - [x] ğŸŸ© Where possible, log request duration (webhook received â†’ reply sent) to detect cold-start latency (fallback: Vercel Edge).
  - [x] ğŸŸ© Where possible, log per-upload extraction outcome (e.g. total chars, page count, errors) to detect messy PDFs (fallback: LlamaParse/Unstructured.io).

---

*Reference: `margai-ghost-tutor-pilot/EXPLORATION.md` for full flows, schema, edge cases, and risks.*
